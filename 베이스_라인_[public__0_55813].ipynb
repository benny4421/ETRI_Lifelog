{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hgziZCG__AC3",
        "ybuDtSKSuivs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LGBM"
      ],
      "metadata": {
        "id": "88auPlbC9a3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 import"
      ],
      "metadata": {
        "id": "dQPreH70lh4Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h46RU-gNcEJj",
        "outputId": "14ee75f6-b149-4292-b950-82c95e5e75ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ast\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "eJ0BkxNkf01P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed 고정\n",
        "SD = 42\n",
        "random.seed(SD)\n",
        "np.random.seed(SD)\n",
        "os.environ['PYTHONHASHSEED'] = str(SD)"
      ],
      "metadata": {
        "id": "RuPZU7og9khw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing"
      ],
      "metadata": {
        "id": "Kgs6iERh9CzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 로드"
      ],
      "metadata": {
        "id": "hgziZCG__AC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 경로 설정\n",
        "data_dir = '/content/drive/MyDrive/ETRI_lifelog_dataset/ch2025_data_items'\n",
        "\n",
        "# Parquet 파일 전체 경로 리스트\n",
        "parquet_files = glob.glob(os.path.join(data_dir, 'ch2025_*.parquet'))"
      ],
      "metadata": {
        "id": "hOw3JzhwgWcO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 이름을 키로, DataFrame을 값으로 저장할 딕셔너리\n",
        "lifelog_data = {}\n",
        "\n",
        "# 파일별로 읽기\n",
        "for file_path in parquet_files:\n",
        "    name = os.path.basename(file_path).replace('.parquet', '').replace('ch2025_', '')\n",
        "    lifelog_data[name] = pd.read_parquet(file_path)\n",
        "    print(f\"✅ Loaded: {name}, shape = {lifelog_data[name].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hns0k9zvhGuY",
        "outputId": "df86a75d-56a1-4446-b36c-bf0fca8188a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded: mActivity, shape = (961062, 3)\n",
            "✅ Loaded: mACStatus, shape = (939896, 3)\n",
            "✅ Loaded: mAmbience, shape = (476577, 3)\n",
            "✅ Loaded: mBle, shape = (21830, 3)\n",
            "✅ Loaded: mLight, shape = (96258, 3)\n",
            "✅ Loaded: mGps, shape = (800611, 3)\n",
            "✅ Loaded: mUsageStats, shape = (45197, 3)\n",
            "✅ Loaded: mScreenStatus, shape = (939653, 3)\n",
            "✅ Loaded: wHr, shape = (382918, 3)\n",
            "✅ Loaded: mWifi, shape = (76336, 3)\n",
            "✅ Loaded: wLight, shape = (633741, 3)\n",
            "✅ Loaded: wPedo, shape = (748100, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 딕셔너리에 있는 모든 항목을 독립적인 변수로 할당\n",
        "for key, df in lifelog_data.items():\n",
        "    globals()[f\"{key}_df\"] = df"
      ],
      "metadata": {
        "id": "Z6o6qm8ob4xC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lifelog_date가 timestamp랑 같다\n",
        "metrics_train = pd.read_csv('/content/drive/MyDrive/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/ETRI_lifelog_dataset/ch2025_submission_sample.csv')"
      ],
      "metadata": {
        "id": "eo6L8gHpPT2n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 기준 쌍 (subject_id, lifelog_date)\n",
        "sample_submission['lifelog_date'] = pd.to_datetime(sample_submission['lifelog_date'])\n",
        "test_keys = set(zip(sample_submission['subject_id'], sample_submission['lifelog_date'].dt.date))\n",
        "\n",
        "# ✅ DataFrame 별 timestamp 컬럼 수동 지정\n",
        "dataframes = {\n",
        "    'mACStatus': (mACStatus_df, 'timestamp'),\n",
        "    'mActivity': (mActivity_df, 'timestamp'),\n",
        "    'mAmbience': (mAmbience_df, 'timestamp'),\n",
        "    'mBle': (mBle_df, 'timestamp'),\n",
        "    'mGps': (mGps_df, 'timestamp'),\n",
        "    'mLight': (mLight_df, 'timestamp'),\n",
        "    'mScreenStatus': (mScreenStatus_df, 'timestamp'),\n",
        "    'mUsageStats': (mUsageStats_df, 'timestamp'),\n",
        "    'mWifi': (mWifi_df, 'timestamp'),\n",
        "    'wHr': (wHr_df, 'timestamp'),\n",
        "    'wLight': (wLight_df, 'timestamp'),\n",
        "    'wPedo': (wPedo_df, 'timestamp'),\n",
        "}\n",
        "\n",
        "# ✅ 분리 함수\n",
        "def split_test_train(df, subject_col='subject_id', timestamp_col='timestamp'):\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors='coerce')\n",
        "    df = df.dropna(subset=[timestamp_col])\n",
        "    df['date_only'] = df[timestamp_col].dt.date\n",
        "    df['key'] = list(zip(df[subject_col], df['date_only']))\n",
        "\n",
        "    test_df = df[df['key'].isin(test_keys)].drop(columns=['date_only', 'key'])\n",
        "    train_df = df[~df['key'].isin(test_keys)].drop(columns=['date_only', 'key'])\n",
        "    return test_df, train_df\n",
        "\n",
        "# ✅ 결과 저장\n",
        "for name, (df, ts_col) in dataframes.items():\n",
        "    print(f\"⏳ {name} 분리 중...\")\n",
        "    test_df, train_df = split_test_train(df.copy(), subject_col='subject_id', timestamp_col=ts_col)\n",
        "    globals()[f\"{name}_test\"] = test_df\n",
        "    globals()[f\"{name}_train\"] = train_df\n",
        "    print(f\"✅ {name}_test → {test_df.shape}, {name}_train → {train_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MPug0C1VY2Z",
        "outputId": "b1c89b0d-2c89-43e0-f9f4-268b97ab3363"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ mACStatus 분리 중...\n",
            "✅ mACStatus_test → (335849, 3), mACStatus_train → (604047, 3)\n",
            "⏳ mActivity 분리 중...\n",
            "✅ mActivity_test → (343579, 3), mActivity_train → (617483, 3)\n",
            "⏳ mAmbience 분리 중...\n",
            "✅ mAmbience_test → (170453, 3), mAmbience_train → (306124, 3)\n",
            "⏳ mBle 분리 중...\n",
            "✅ mBle_test → (8140, 3), mBle_train → (13690, 3)\n",
            "⏳ mGps 분리 중...\n",
            "✅ mGps_test → (287386, 3), mGps_train → (513225, 3)\n",
            "⏳ mLight 분리 중...\n",
            "✅ mLight_test → (34439, 3), mLight_train → (61819, 3)\n",
            "⏳ mScreenStatus 분리 중...\n",
            "✅ mScreenStatus_test → (336160, 3), mScreenStatus_train → (603493, 3)\n",
            "⏳ mUsageStats 분리 중...\n",
            "✅ mUsageStats_test → (16499, 3), mUsageStats_train → (28698, 3)\n",
            "⏳ mWifi 분리 중...\n",
            "✅ mWifi_test → (27467, 3), mWifi_train → (48869, 3)\n",
            "⏳ wHr 분리 중...\n",
            "✅ wHr_test → (143311, 3), wHr_train → (239607, 3)\n",
            "⏳ wLight 분리 중...\n",
            "✅ wLight_test → (233809, 3), wLight_train → (399932, 3)\n",
            "⏳ wPedo 분리 중...\n",
            "✅ wPedo_test → (288832, 9), wPedo_train → (459268, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 분단위 -> 하루 단위 def"
      ],
      "metadata": {
        "id": "ybuDtSKSuivs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mACStatus(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "    df = df.sort_values(['subject_id', 'timestamp'])\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        status = group['m_charging'].values  # 0/1 상태\n",
        "        times = group['timestamp'].values\n",
        "\n",
        "        # 충전 상태 비율\n",
        "        ratio_charging = status.mean()\n",
        "\n",
        "        # 상태 전이 횟수\n",
        "        transitions = (status[1:] != status[:-1]).sum()\n",
        "\n",
        "        # 연속된 1 상태 길이들\n",
        "        lengths = []\n",
        "        current_len = 0\n",
        "        for val in status:\n",
        "            if val == 1:\n",
        "                current_len += 1\n",
        "            elif current_len > 0:\n",
        "                lengths.append(current_len)\n",
        "                current_len = 0\n",
        "        if current_len > 0:\n",
        "            lengths.append(current_len)\n",
        "\n",
        "        avg_charging_duration = np.mean(lengths) if lengths else 0\n",
        "        max_charging_duration = np.max(lengths) if lengths else 0\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': subj,\n",
        "            'date': date,\n",
        "            'charging_ratio': ratio_charging,\n",
        "            'charging_transitions': transitions,\n",
        "            'avg_charging_duration': avg_charging_duration,\n",
        "            'max_charging_duration': max_charging_duration,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "mACStatus_df2 = process_mACStatus(mACStatus_df)"
      ],
      "metadata": {
        "id": "N3dswJou4PGl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mActivity(df):\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    summary = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        counts = group['m_activity'].value_counts(normalize=True)  # 비율\n",
        "        row = {'subject_id': subj, 'date': date}\n",
        "\n",
        "        # 0~8 비율 저장\n",
        "        for i in range(9):\n",
        "            row[f'activity_{i}_ratio'] = counts.get(i, 0)\n",
        "\n",
        "        # 주요 활동 정보\n",
        "        row['dominant_activity'] = group['m_activity'].mode()[0]\n",
        "        row['num_unique_activities'] = group['m_activity'].nunique()\n",
        "\n",
        "        summary.append(row)\n",
        "\n",
        "    return pd.DataFrame(summary)\n",
        "\n",
        "mActivity_df2 = process_mActivity(mActivity_df)"
      ],
      "metadata": {
        "id": "ahAmyl1S6937"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지정된 10개 라벨\n",
        "top_10_labels = [\n",
        "    \"Inside, small room\", \"Speech\", \"Silence\", \"Music\",\n",
        "    \"Narration, monologue\", \"Child speech, kid speaking\",\n",
        "    \"Conversation\", \"Speech synthesizer\", \"Shout\", \"Babbling\"\n",
        "]\n",
        "\n",
        "def process_mAmbience_top10(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    # 초기화\n",
        "    for label in top_10_labels + ['others']:\n",
        "        df[label] = 0.0\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        parsed = ast.literal_eval(row['m_ambience']) if isinstance(row['m_ambience'], str) else row['m_ambience']\n",
        "        others_prob = 0.0\n",
        "\n",
        "        for label, prob in parsed:\n",
        "            prob = float(prob)\n",
        "            if label in top_10_labels:\n",
        "                df.at[idx, label] = prob\n",
        "            else:\n",
        "                others_prob += prob\n",
        "\n",
        "        df.at[idx, 'others'] = others_prob\n",
        "\n",
        "    return df.drop(columns=['m_ambience'])\n",
        "\n",
        "mAmbience_df2= process_mAmbience_top10(mAmbience_df)\n",
        "\n",
        "def summarize_mAmbience_daily(df):\n",
        "    prob_cols = [col for col in df.columns if col not in ['subject_id', 'timestamp', 'date']]\n",
        "\n",
        "    # 하루 단위로 평균값 요약\n",
        "    daily_summary = df.groupby(['subject_id', 'date'])[prob_cols].mean().reset_index()\n",
        "    return daily_summary\n",
        "\n",
        "mAmbience_df2 = summarize_mAmbience_daily(mAmbience_df2)"
      ],
      "metadata": {
        "id": "uMYc3WNwAyG0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mBle(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        entry = ast.literal_eval(row['m_ble']) if isinstance(row['m_ble'], str) else row['m_ble']\n",
        "\n",
        "        rssi_list = []\n",
        "        class_0_cnt = 0\n",
        "        class_other_cnt = 0\n",
        "\n",
        "        for device in entry:\n",
        "            try:\n",
        "                rssi = int(device['rssi'])\n",
        "                rssi_list.append(rssi)\n",
        "\n",
        "                if str(device['device_class']) == '0':\n",
        "                    class_0_cnt += 1\n",
        "                else:\n",
        "                    class_other_cnt += 1\n",
        "            except:\n",
        "                continue  # malformed record\n",
        "\n",
        "        feature = {\n",
        "            'subject_id': row['subject_id'],\n",
        "            'date': row['date'],\n",
        "            'device_class_0_cnt': class_0_cnt,\n",
        "            'device_class_others_cnt': class_other_cnt,\n",
        "            'device_count': len(rssi_list),\n",
        "            'rssi_mean': np.mean(rssi_list) if rssi_list else np.nan,\n",
        "            'rssi_min': np.min(rssi_list) if rssi_list else np.nan,\n",
        "            'rssi_max': np.max(rssi_list) if rssi_list else np.nan,\n",
        "        }\n",
        "        features.append(feature)\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "def summarize_mBle_daily(df):\n",
        "    # row 단위 BLE feature 추출\n",
        "    df = process_mBle(df)\n",
        "\n",
        "    # 하루 단위로 cnt 합치기\n",
        "    grouped = df.groupby(['subject_id', 'date']).agg({\n",
        "        'device_class_0_cnt': 'sum',\n",
        "        'device_class_others_cnt': 'sum',\n",
        "        'rssi_mean': 'mean',\n",
        "        'rssi_min': 'min',\n",
        "        'rssi_max': 'max',\n",
        "    }).reset_index()\n",
        "\n",
        "    # 총합 구해서 비율 계산\n",
        "    total_cnt = grouped['device_class_0_cnt'] + grouped['device_class_others_cnt']\n",
        "    grouped['device_class_0_ratio'] = grouped['device_class_0_cnt'] / total_cnt.replace(0, np.nan)\n",
        "    grouped['device_class_others_ratio'] = grouped['device_class_others_cnt'] / total_cnt.replace(0, np.nan)\n",
        "\n",
        "    # 필요 없는 원래 cnt 컬럼 제거\n",
        "    grouped.drop(columns=['device_class_0_cnt', 'device_class_others_cnt'], inplace=True)\n",
        "\n",
        "    return grouped\n",
        "\n",
        "mBle_df2 = summarize_mBle_daily(mBle_df)"
      ],
      "metadata": {
        "id": "-m7j1Yc1EDrP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mGps(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        gps_list = ast.literal_eval(row['m_gps']) if isinstance(row['m_gps'], str) else row['m_gps']\n",
        "\n",
        "        altitudes = []\n",
        "        latitudes = []\n",
        "        longitudes = []\n",
        "        speeds = []\n",
        "\n",
        "        for entry in gps_list:\n",
        "            try:\n",
        "                altitudes.append(float(entry['altitude']))\n",
        "                latitudes.append(float(entry['latitude']))\n",
        "                longitudes.append(float(entry['longitude']))\n",
        "                speeds.append(float(entry['speed']))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        features.append({\n",
        "            'subject_id': row['subject_id'],\n",
        "            'date': row['date'],\n",
        "            'altitude_mean': np.mean(altitudes) if altitudes else np.nan,\n",
        "            'latitude_std': np.std(latitudes) if latitudes else np.nan,\n",
        "            'longitude_std': np.std(longitudes) if longitudes else np.nan,\n",
        "            'speed_mean': np.mean(speeds) if speeds else np.nan,\n",
        "            'speed_max': np.max(speeds) if speeds else np.nan,\n",
        "            'speed_std': np.std(speeds) if speeds else np.nan,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "m_Gps_df2 = process_mGps(mGps_df)\n",
        "\n",
        "m_Gps_df2 = m_Gps_df2.groupby(['subject_id', 'date']).agg({\n",
        "    'altitude_mean': 'mean',\n",
        "    'latitude_std': 'mean',\n",
        "    'longitude_std': 'mean',\n",
        "    'speed_mean': 'mean',\n",
        "    'speed_max': 'max',\n",
        "    'speed_std': 'mean'\n",
        "}).reset_index()"
      ],
      "metadata": {
        "id": "oyL7ADbUNP_z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mLight(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "\n",
        "    # 밤(22~05시), 낮(06~21시) 구분\n",
        "    df['is_night'] = df['hour'].apply(lambda h: h >= 22 or h < 6)\n",
        "\n",
        "    # 하루 단위 요약\n",
        "    daily = df.groupby(['subject_id', 'date']).agg(\n",
        "        light_mean=('m_light', 'mean'),\n",
        "        light_std=('m_light', 'std'),\n",
        "        light_max=('m_light', 'max'),\n",
        "        light_min=('m_light', 'min'),\n",
        "        light_night_mean=('m_light', lambda x: x[df.loc[x.index, 'is_night']].mean()),\n",
        "        light_day_mean=('m_light', lambda x: x[~df.loc[x.index, 'is_night']].mean()),\n",
        "        light_night_ratio=('is_night', 'mean')  # 밤 시간 측정 비율\n",
        "    ).reset_index()\n",
        "\n",
        "    return daily\n",
        "\n",
        "mLight_df2 = process_mLight(mLight_df)"
      ],
      "metadata": {
        "id": "-QXkKcr7ODUi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mScreenStatus(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        status = group['m_screen_use'].values\n",
        "        ratio_on = status.mean()\n",
        "        transitions = (status[1:] != status[:-1]).sum()\n",
        "\n",
        "        # 연속된 1 상태 길이들\n",
        "        durations = []\n",
        "        current = 0\n",
        "        for val in status:\n",
        "            if val == 1:\n",
        "                current += 1\n",
        "            elif current > 0:\n",
        "                durations.append(current)\n",
        "                current = 0\n",
        "        if current > 0:\n",
        "            durations.append(current)\n",
        "\n",
        "        features.append({\n",
        "            'subject_id': subj,\n",
        "            'date': date,\n",
        "            'screen_on_ratio': ratio_on,\n",
        "            'screen_on_transitions': transitions,\n",
        "            'screen_on_duration_avg': np.mean(durations) if durations else 0,\n",
        "            'screen_on_duration_max': np.max(durations) if durations else 0,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "mScreenStatus_df2 = process_mScreenStatus(mScreenStatus_df)"
      ],
      "metadata": {
        "id": "C72VGXW3O2Gt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_apps = [\n",
        "    'One UI 홈', '카카오톡', '시스템 UI', 'NAVER', '캐시워크', '성경일독Q',\n",
        "    'YouTube', '통화', '메시지', '타임스프레드', 'Instagram']\n",
        "\n",
        "def process_mUsageStats(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        app_time = {app: 0 for app in top_apps}\n",
        "        others_time = 0\n",
        "\n",
        "        for row in group['m_usage_stats']:\n",
        "            parsed = ast.literal_eval(row) if isinstance(row, str) else row\n",
        "            for entry in parsed:\n",
        "                app = entry.get('app_name')\n",
        "                time = entry.get('total_time', 0)\n",
        "                if app in top_apps:\n",
        "                    app_time[app] += int(time)\n",
        "                else:\n",
        "                    others_time += int(time)\n",
        "\n",
        "        feature = {\n",
        "            'subject_id': subj,\n",
        "            'date': date,\n",
        "            'others_time': others_time\n",
        "        }\n",
        "        # 각 앱별 컬럼 추가\n",
        "        feature.update({f'{app}_time': app_time[app] for app in top_apps})\n",
        "\n",
        "        features.append(feature)\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "mUsageStats_df2 = process_mUsageStats(mUsageStats_df)"
      ],
      "metadata": {
        "id": "bzzmA6ZYVqvR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_mWifi(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        rssi_all = []\n",
        "\n",
        "        for row in group['m_wifi']:\n",
        "            parsed = ast.literal_eval(row) if isinstance(row, str) else row\n",
        "            for ap in parsed:\n",
        "                try:\n",
        "                    rssi = int(ap['rssi'])\n",
        "                    rssi_all.append(rssi)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': subj,\n",
        "            'date': date,\n",
        "            'wifi_rssi_mean': np.mean(rssi_all) if rssi_all else np.nan,\n",
        "            'wifi_rssi_min': np.min(rssi_all) if rssi_all else np.nan,\n",
        "            'wifi_rssi_max': np.max(rssi_all) if rssi_all else np.nan,\n",
        "            'wifi_detected_cnt': len(rssi_all)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "mWifi_df2 = process_mWifi(mWifi_df)"
      ],
      "metadata": {
        "id": "WACOMvLUW1va"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_block(hour):\n",
        "    if 0 <= hour < 6:\n",
        "        return 'early_morning'\n",
        "    elif 6 <= hour < 12:\n",
        "        return 'morning'\n",
        "    elif 12 <= hour < 18:\n",
        "        return 'afternoon'\n",
        "    else:\n",
        "        return 'evening'\n",
        "\n",
        "def process_wHr_by_timeblock(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        block_stats = {'subject_id': subj, 'date': date}\n",
        "\n",
        "        for block, block_group in group.groupby('block'):\n",
        "            hr_all = []\n",
        "            for row in block_group['heart_rate']:\n",
        "                parsed = ast.literal_eval(row) if isinstance(row, str) else row\n",
        "                hr_all.extend([int(h) for h in parsed if h is not None])\n",
        "\n",
        "            if not hr_all:\n",
        "                continue\n",
        "\n",
        "            above_100 = [hr for hr in hr_all if hr > 100]\n",
        "            block_stats[f'hr_{block}_mean'] = np.mean(hr_all)\n",
        "            block_stats[f'hr_{block}_std'] = np.std(hr_all)\n",
        "            block_stats[f'hr_{block}_max'] = np.max(hr_all)\n",
        "            block_stats[f'hr_{block}_min'] = np.min(hr_all)\n",
        "            block_stats[f'hr_{block}_above_100_ratio'] = len(above_100) / len(hr_all)\n",
        "\n",
        "        results.append(block_stats)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "wHr_df2 = process_wHr_by_timeblock(wHr_df)"
      ],
      "metadata": {
        "id": "7FBiJ4fnYLf2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_block(hour):\n",
        "    if 0 <= hour < 6:\n",
        "        return 'early_morning'\n",
        "    elif 6 <= hour < 12:\n",
        "        return 'morning'\n",
        "    elif 12 <= hour < 18:\n",
        "        return 'afternoon'\n",
        "    else:\n",
        "        return 'evening'\n",
        "\n",
        "def process_wLight_by_timeblock(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subj, date), group in df.groupby(['subject_id', 'date']):\n",
        "        block_stats = {'subject_id': subj, 'date': date}\n",
        "\n",
        "        for block, block_group in group.groupby('block'):\n",
        "            lux = block_group['w_light'].dropna().values\n",
        "            if len(lux) == 0:\n",
        "                continue\n",
        "\n",
        "            block_stats[f'wlight_{block}_mean'] = np.mean(lux)\n",
        "            block_stats[f'wlight_{block}_std'] = np.std(lux)\n",
        "            block_stats[f'wlight_{block}_max'] = np.max(lux)\n",
        "            block_stats[f'wlight_{block}_min'] = np.min(lux)\n",
        "\n",
        "        results.append(block_stats)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "wLight_df2 = process_wLight_by_timeblock(wLight_df)"
      ],
      "metadata": {
        "id": "Gr5ClTYbZEUt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_wPedo(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['date'] = df['timestamp'].dt.date\n",
        "\n",
        "    summary = df.groupby(['subject_id', 'date']).agg({\n",
        "        'step': 'sum',\n",
        "        'step_frequency': 'mean',\n",
        "        'distance': 'sum',\n",
        "        'speed': ['mean', 'max'],\n",
        "        'burned_calories': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    # 컬럼 이름 정리\n",
        "    summary.columns = ['subject_id', 'date',\n",
        "                       'step_sum', 'step_frequency_mean',\n",
        "                       'distance_sum', 'speed_mean', 'speed_max',\n",
        "                       'burned_calories_sum']\n",
        "\n",
        "    return summary\n",
        "\n",
        "wPedo_df2 = process_wPedo(wPedo_df)"
      ],
      "metadata": {
        "id": "CPYQL1f4ZcAT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### df 합치기"
      ],
      "metadata": {
        "id": "6noR1u7GZ1cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "\n",
        "df_list = [\n",
        "    mACStatus_df2,\n",
        "    mActivity_df2,\n",
        "    mAmbience_df2,\n",
        "    mBle_df2,\n",
        "    m_Gps_df2,\n",
        "    mLight_df2,\n",
        "    mScreenStatus_df2,\n",
        "    mUsageStats_df2,\n",
        "    mWifi_df2,\n",
        "    wHr_df2,\n",
        "    wHr_df2,\n",
        "    wLight_df2,\n",
        "    wPedo_df2\n",
        "]\n",
        "\n",
        "merged_df = reduce(lambda left, right: pd.merge(left, right, on=['subject_id', 'date'], how='outer'), df_list)"
      ],
      "metadata": {
        "id": "mG4UCJMBZ5Up"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics_train의 lifelog_date → datetime.date 형으로 변환\n",
        "metrics_train['lifelog_date'] = pd.to_datetime(metrics_train['lifelog_date']).dt.date\n",
        "\n",
        "# merged_df의 date도 변환\n",
        "merged_df['date'] = pd.to_datetime(merged_df['date']).dt.date\n",
        "\n",
        "# 1. date 기준 정렬을 위해 metrics_train의 lifelog_date -> date로 맞추기\n",
        "metrics_train_renamed = metrics_train.rename(columns={'lifelog_date': 'date'})\n",
        "\n",
        "# 2. train_df: metrics_train과 일치하는 (subject_id, date) → 라벨 포함\n",
        "train_df = pd.merge(metrics_train_renamed, merged_df, on=['subject_id', 'date'], how='inner')\n",
        "\n",
        "# 3. test_df: metrics_train에 없는 (subject_id, date)\n",
        "merged_keys = merged_df[['subject_id', 'date']]\n",
        "train_keys = metrics_train_renamed[['subject_id', 'date']]\n",
        "test_keys = pd.merge(merged_keys, train_keys, on=['subject_id', 'date'], how='left', indicator=True)\n",
        "test_keys = test_keys[test_keys['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
        "\n",
        "test_df = pd.merge(test_keys, merged_df, on=['subject_id', 'date'], how='left')"
      ],
      "metadata": {
        "id": "5Gb9JDXoZ9oM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링"
      ],
      "metadata": {
        "id": "zTPy9k120w6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 타겟 리스트\n",
        "targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n",
        "target_multiclass = 'S1'\n",
        "\n",
        "# ✅ feature 준비\n",
        "X = train_df.drop(columns=['subject_id', 'sleep_date', 'date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3'])\n",
        "X.fillna(0, inplace=True)  # 결측값 처리\n",
        "\n",
        "test_X = test_df.drop(columns=['subject_id', 'date'])\n",
        "test_X.fillna(0, inplace=True)\n",
        "\n",
        "# 컬럼 이름에서 특수 문자 제거/변환\n",
        "def sanitize_column_names(df):\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "        .str.replace(r\"[^\\w]\", \"_\", regex=True)  # 특수문자 → _\n",
        "        .str.replace(r\"__+\", \"_\", regex=True)    # 연속된 _ 제거\n",
        "        .str.strip(\"_\")                          # 앞뒤 _ 제거\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# 모든 입력에 적용\n",
        "X = sanitize_column_names(X)\n",
        "test_X = sanitize_column_names(test_X)"
      ],
      "metadata": {
        "id": "NksL8xiz_3Oh"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 저장\n",
        "binary_preds = {}\n",
        "multiclass_pred = None\n",
        "\n",
        "common_params = {\n",
        "    'n_estimators': 1000,\n",
        "    'learning_rate': 0.03,\n",
        "    'random_state': 42,\n",
        "    'n_jobs': -1,\n",
        "    'verbosity': -1\n",
        "}\n",
        "\n",
        "# 이진 분류 학습\n",
        "for col in targets_binary:\n",
        "    y = train_df[col]\n",
        "    model = LGBMClassifier(**common_params)\n",
        "    model.fit(X, y)\n",
        "    binary_preds[col] = model.predict(test_X)  # 🔥 확률X, 클래스 직접 예측\n",
        "\n",
        "# 다중 분류 학습 (S1)\n",
        "y_multi = train_df['S1']\n",
        "model_s1 = LGBMClassifier(**common_params, objective='multiclass', num_class=3)\n",
        "model_s1.fit(X, y_multi)\n",
        "multiclass_pred = model_s1.predict(test_X)  # 🔥 클래스 직접 예측"
      ],
      "metadata": {
        "id": "oKpKyAngzkQ4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importance 출력\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': model_s1.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 100))\n",
        "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "-J3OYiyHlXjV",
        "outputId": "e9624a0a-ec78-40e6-e56e-43468a030c5e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-41b51ec2a898>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importance 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m feature_importance = pd.DataFrame({\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'feature'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'importance'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_s1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }).sort_values('importance', ascending=False)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample 기반 제출 포맷 가져오기\n",
        "submission_final = sample_submission[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "\n",
        "# lifelog_date 기준으로 string → date 형식 통일\n",
        "submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n",
        "\n",
        "# ID 만들기 (submission에서 예측한 결과와 연결하기 위해)\n",
        "submission_final['ID'] = submission_final['subject_id'] + '_' + submission_final['lifelog_date'].astype(str)\n",
        "\n",
        "# 예측 결과 연결할 수 있도록 동일한 순서로 정렬\n",
        "# 보통 예측 결과는 test_df 기준이므로 정렬 보장되어야 함\n",
        "assert len(submission_final) == len(multiclass_pred)  # shape 체크\n",
        "\n",
        "# 다중 분류 예측 붙이기\n",
        "submission_final['S1'] = multiclass_pred\n",
        "\n",
        "# 이진 분류 결과 붙이기\n",
        "for col in ['Q1', 'Q2', 'Q3', 'S2', 'S3']:\n",
        "    submission_final[col] = binary_preds[col].astype(int)  # 확률 아닌 class 예측\n",
        "\n",
        "# 최종 제출 형식 정렬\n",
        "submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n",
        "\n",
        "# 저장\n",
        "submission_final.to_csv(\"submission_final.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"submission_final.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "oQ7h8rOd1H6o",
        "outputId": "5fb39377-bc08-48bb-c500-682d5796c293"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28e84404-1c69-48c7-b4ac-fa94340d2666\", \"submission_final.csv\", 9803)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}